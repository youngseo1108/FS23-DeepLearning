{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 7: Transfer Learning\n",
    "\n",
    "\n",
    "The goal of this exercise is to learn how to use pre-trained networks in transfer learning tasks.\n",
    "We will make use of networks trained on ImageNet, and apply them to related problems, i.e., the classification of $10$ objects not contained in ImageNet."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "For this exercise we use the  [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset that can be downloaded from the official website [here]({https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz}).\n",
    "The dataset contains $60000$ color images of pixels size $32\\times 32$ in $10$ classes: airplane, automobile, bird, cat, deer, dog, frog, horse, ship and truck, with $6000$ images per class."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Data Transformation\n",
    "\n",
    "We need to instantiate a proper `torchvision.transform` instance to create the same input structure as used for training our network.\n",
    "We need to combine 4 transforms, which can be compiled from the PyTorch website: https://pytorch.org/vision/stable/models.html\n",
    "\n",
    "1. We need to resize the image such that the shorter side has size 256.\n",
    "2. We need to take the center crop of size $224\\times224$ from the image.\n",
    "3. We need to convert the image into a tensor (including pixel values scaling)\n",
    "4. We need to normalize the pixel values with mean $(0.485, 0.456, 0.406)$ and standard deviation $(0.229, 0.224, 0.225)$.\n",
    "\n",
    "Since we will use networks pre-trained on ImageNet, we need to perform the exact same transform as used for ImageNet testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "# Apply it to the input image\n",
    "imagenet_transform = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.Resize(256), # resize the image such that the shorter side has size 256.\n",
    "     torchvision.transforms.CenterCrop((224, 224)), # take the center crop of size 224*224 from the image.\n",
    "     torchvision.transforms.ToTensor(), # convert the image into a tensor (including pixel values scaling)\n",
    "     torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))] # normalize the pixel values with mean (0.485, 0.456, 0.406) and sd (0.229, 0.224, 0.225).\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Dataset Loading\n",
    "\n",
    "We here use the [torchvision.datasets.CIFAR10](https://pytorch.org/vision/0.12/generated/torchvision.datasets.CIFAR10.html) dataset interface for processing images. \n",
    "You can use the `train` argument or flag to distinguish between training and test set.\n",
    "\n",
    "This task consists of two parts:\n",
    "\n",
    "1. Create two datasets, one for the training set, one for the test set. Use the transform defined above.\n",
    "2. Once the datasets are created, create two data loaders, one for training set, one for test set. Use a proper value of the batch-size $B$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(\n",
    "  root = \"./data\",\n",
    "  train=True, download=True, transform=imagenet_transform\n",
    ")\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "  root = \"./data\",\n",
    "  train=False, download=True, transform=imagenet_transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 16\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=B, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=B, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1: Data Size and Types\n",
    "\n",
    "We check that all input images are `torch.tensors` of size $3\\times224\\times224$ and of type `torch.float` and that all labels are of type `int`.\n",
    "\n",
    "Note: the sanity check is only performed on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, t in testset:\n",
    "  assert isinstance(x, torch.Tensor)\n",
    "  assert isinstance(t, int)\n",
    "  assert x.shape==(3,224,224)\n",
    "  assert x.dtype==torch.float"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Pre-trained Network Instantiation\n",
    "\n",
    "Instantiate two pre-trained networks of type ResNet-50.\n",
    "\n",
    "1. Freeze the feature layers of the first network.\n",
    "\n",
    "Note: Make use the `old TorchVision Interface` to load your pre-trained network. Here is the link: https://pytorch.org/vision/0.12/models.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\0youn\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\0youn\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# instantiate the first pre-trained resnet 50 network\n",
    "network_1 = torchvision.models.resnet50(pretrained=True)\n",
    "# Make sure to freeze all the layers of the network.\n",
    "# https://androidkt.com/pytorch-freeze-layer-fixed-feature-extractor-transfer-learning/\n",
    "for param in network_1.parameters():\n",
    "    param.required_grad = False\n",
    "\n",
    "# instantiate the second pre-trained resnet 50 network (optinally)\n",
    "network_2 = torchvision.models.resnet50(pretrained=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Network Implementation\n",
    "\n",
    "We want to modify the network such that we extract the logits for the 10 classes from CIFAR-10 from the last fully-connected layer of the network.\n",
    "\n",
    "Implement a function that:\n",
    "1. Replaces the current last linear layer of the pre-trained network with a new linear layer that has $O$ units ($O$ represents the number of classes in our dataset).\n",
    "2. Initialize the weights of the new linear layer using Xavier's method **(Optional)**.\n",
    "\n",
    "Note: Use `torch.nn.init.xavier_uniform_` function to initialize the weights of the new linear layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://discuss.pytorch.org/t/how-to-perform-finetuning-in-pytorch/419/11\n",
    "\n",
    "def replace_last_layer(network, O=10):\n",
    "  # define a new linear layer with the input features of the last linear layer & O units\n",
    "  new_layer = torch.nn.Linear(network.fc.in_features, O, bias=True)\n",
    "  # initialise the weights of the new linear layer using Xavier's method\n",
    "  torch.nn.init.xavier_uniform_(new_layer.weight)\n",
    "  # Replace the last linear layer of the pre-trained model with the new linear layer\n",
    "  network.fc = new_layer\n",
    "  return network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2: Last layer dimensions\n",
    "\n",
    "This test ensures that the function return a network having the correct number of input and output units in the last layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "O = 10\n",
    "for network in (network_1, network_2):\n",
    "    new_model = replace_last_layer(network, O=O)\n",
    "    assert new_model.fc.out_features == O\n",
    "    assert new_model.fc.in_features == 2048"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Training\n",
    "Implement a function that takes all necessary parameters to run a training on a given dataset. \n",
    "Select the optimizer to be `torch.optim.SGD` and `torch.nn.CrossEntropyLoss` as the loss function. \n",
    "The test set will be used as the validation set."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: Training and Evaluation Loop\n",
    "\n",
    "Implement a training loop over a specific number of epochs (10) with a learning rate of $\\eta=0.001$ and momentum of $\\mu = 0.9$. \n",
    "Make sure that you train on the training data only, and `not` on the validation data.\n",
    "In each loop, compute and print the training loss, training accuracy, validation loss and validation accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.learnpytorch.io/06_pytorch_transfer_learning/\n",
    "import numpy as np\n",
    "\n",
    "def train_eval(network, trainloader, testloader, epochs=10, eta=0.001, mu=0.9):\n",
    "    # select loss function and optimizer\n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(\n",
    "        params=network.parameters(),\n",
    "        lr=eta, momentum=mu\n",
    "    )\n",
    "\n",
    "    # instantiate the correct device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    network = network.to(device)\n",
    "\n",
    "    # collect loss & accuracies over training & test epochs\n",
    "    train_loss, train_acc = [], []\n",
    "    test_loss, test_acc = [], []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # training process\n",
    "        train_loss_epoch = []\n",
    "        train_correct = 0\n",
    "        for x,t in trainloader:\n",
    "            # put data to device\n",
    "            optimizer.zero_grad()\n",
    "            x, t = x.to(device), t.to(device)\n",
    "            # train\n",
    "            z = network(x)\n",
    "            J = loss(z, t)\n",
    "            train_loss_epoch.append(J.item())\n",
    "            J.backward()\n",
    "            # perform parameter update\n",
    "            optimizer.step()\n",
    "        # print accuracies and losses for current epoch\n",
    "        train_acc.append(train_correct / len(trainloader))\n",
    "        train_loss.append(np.mean(train_loss_epoch))\n",
    "\n",
    "        # testing process\n",
    "        with torch.no_grad():\n",
    "            loss_epoch = []\n",
    "            correct = 0\n",
    "            for x,t in testloader:\n",
    "                # put data to device\n",
    "                x,t = x.to(device), t.to(device)\n",
    "                # compute validation loss\n",
    "                z = network(x)\n",
    "                J = loss(z, t)\n",
    "                loss_epoch.append(J.item())\n",
    "                # compute valication accuracy\n",
    "                correct += torch.sum(torch.argmax(z, dim=1) == t).item()\n",
    "            # print accuracies and losses for current epoch\n",
    "            test_acc.append(correct / len(testloader))\n",
    "            test_loss.append(np.mean(loss_epoch))\n",
    "            \n",
    "    return train_loss, train_acc, test_loss, test_acc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6: Network Fine-Tuning with Frozen Layers\n",
    "\n",
    "Create a network that has feature layers frozen with $10$ output units. \n",
    "Fine-tune the created network on our CIFAR-10 data using the previous function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m network_with_frozen_layers \u001b[39m=\u001b[39m replace_last_layer(network_1, \u001b[39m10\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m train_eval(network_with_frozen_layers, trainloader, testloader)\n",
      "Cell \u001b[1;32mIn[30], line 32\u001b[0m, in \u001b[0;36mtrain_eval\u001b[1;34m(network, trainloader, testloader, epochs, eta, mu)\u001b[0m\n\u001b[0;32m     30\u001b[0m J \u001b[39m=\u001b[39m loss(z, t)\n\u001b[0;32m     31\u001b[0m train_loss_epoch\u001b[39m.\u001b[39mappend(J\u001b[39m.\u001b[39mitem())\n\u001b[1;32m---> 32\u001b[0m J\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     33\u001b[0m \u001b[39m# perform parameter update\u001b[39;00m\n\u001b[0;32m     34\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\0youn\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\0youn\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "network_with_frozen_layers = replace_last_layer(network_1, 10)\n",
    "train_eval(network_with_frozen_layers, trainloader, testloader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7 (Optional): Network Fine-Tuning without Frozen Layers \n",
    "\n",
    "Create a network from the second pre-trained network with $10$ output units. \n",
    "Fine-tune the created network on our CIFAR-10.\n",
    "\n",
    "Note:\n",
    "\n",
    "  * The fine-tuning of the network can take a long time when the layers are not frozen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_normal = replace_last_layer(network_2, 10)\n",
    "train_eval(network_normal, trainloader, testloader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting\n",
    "\n",
    "Finally, we want to plot the confusion matrix of the test set.\n",
    "For this, we need to compute the predictions for all of our test samples, and the list of target values.\n",
    "Finally, we can make use of the `sklearn.metrics.confusion_matrix` to compute the confusion matrix.\n",
    "You can utilize `sklearn.metrics.ConfusionMatrixDisplay` for displaying the confusion matrix, or `pyplot.imshow` and adding the according labels.\n",
    "\n",
    "Note:\n",
    "\n",
    "  * The documentation for the confusion matrix can be found here: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n",
    "  * The interface and an example for the `ConfusionMatrixDisplay` can be found here: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8: Confusion Matrix Plotting\n",
    "\n",
    "Plot the confusion matrix for the fine-tuned network with frozen layers.\n",
    "Optionally, also plot the confusion matrix for the second fine-tuned network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# compute predictions and collect targets\n",
    "predictions = ...\n",
    "targets = ...\n",
    "\n",
    "# compute confusion matrix\n",
    "matrix = confusion_matrix(...)\n",
    "\n",
    "# plot confusion matrix\n",
    "...\n",
    "\n",
    "# add axis labels if required\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "X, y = make_classification(random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "clf = SVC(random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(clf.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, predictions, labels=clf.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf.classes_)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2dd53f8ad749bca69f7250ce75eb4f0def59db5cf79075a9716322ffc58e8a2e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('DL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
